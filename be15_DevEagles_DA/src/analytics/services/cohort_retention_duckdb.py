"""
ì½”í˜¸íŠ¸ ë¦¬í…ì…˜ ë¶„ì„ ì„œë¹„ìŠ¤ - DuckDB ë²„ì „

DuckDBì—ì„œ ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ì—¬ ì½”í˜¸íŠ¸ ë¦¬í…ì…˜ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
"""

import pandas as pd
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import warnings
import os
import matplotlib.font_manager as fm

from analytics.core.logging import get_logger
from analytics.core.database import get_analytics_db, get_crm_db

# í•œê¸€ í°íŠ¸ ì„¤ì •
font_candidates = [
    (r"C:/Windows/Fonts/malgun.ttf", "Malgun Gothic"),
    ("/usr/share/fonts/truetype/nanum/NanumGothic.ttf", "NanumGothic")
]

for fp, family in font_candidates:
    if os.path.exists(fp):
        fm.fontManager.addfont(fp)
        plt.rc("font", family=family)
        break
else:
    plt.rcParams['font.family'] = 'DejaVu Sans'

plt.rcParams['axes.unicode_minus'] = False


class CohortRetentionAnalyzerDuckDB:
    """ì½”í˜¸íŠ¸ ë¦¬í…ì…˜ ë¶„ì„ê¸° - DuckDB ë²„ì „"""
    
    def __init__(self):
        self.logger = get_logger(__name__)
        self.analytics_db = get_analytics_db()
        self.crm_db = get_crm_db()
        self.customer_data = None
        self.reservation_data = None
        self.cohort_data = None
        self.sales_data = None
        
    def load_data(self):
        """DuckDBì—ì„œ ë°ì´í„° ë¡œë”©"""
        self.logger.info("ğŸ“Š DuckDBì—ì„œ ì½”í˜¸íŠ¸ ë¶„ì„ ë°ì´í„° ë¡œë”© ì¤‘...")
        
        try:
            # ê³ ê° ë°ì´í„° ë¡œë“œ (ë‹¨ìˆ˜í˜• í…Œì´ë¸”ëª…)
            self.logger.info("ê³ ê° ë°ì´í„° ë¡œë”©...")
            customer_query = "SELECT * FROM customer"
            self.customer_data = self.analytics_db.execute(customer_query).fetchdf()
            
            # ì˜ˆì•½ ë°ì´í„° ë¡œë“œ (ìµœê·¼ 1ë…„, ë‹¨ìˆ˜í˜• í…Œì´ë¸”ëª…)
            self.logger.info("ì˜ˆì•½ ë°ì´í„° ë¡œë”©...")
            reservation_query = """
            SELECT * FROM reservation 
            WHERE reservation_start_at >= NOW() - INTERVAL 365 DAY
            """
            self.reservation_data = self.analytics_db.execute(reservation_query).fetchdf()
            
            # ë§¤ì¶œ ë°ì´í„° ë¡œë“œ (ìµœê·¼ 1ë…„)
            self.logger.info("ë§¤ì¶œ ë°ì´í„° ë¡œë”©...")
            sales_query = """
            SELECT * FROM sales 
            WHERE sales_date >= NOW() - INTERVAL 365 DAY
            """
            self.sales_data = self.analytics_db.execute(sales_query).fetchdf()
            
            self.logger.info(f"âœ… ë¡œë“œ ì™„ë£Œ - ê³ ê°: {len(self.customer_data):,}ëª…, "
                           f"ì˜ˆì•½: {len(self.reservation_data):,}ê±´, "
                           f"ë§¤ì¶œ: {len(self.sales_data):,}ê±´")
            
            # ë‚ ì§œ ì»¬ëŸ¼ ë³€í™˜
            if 'recent_visit_date' in self.customer_data.columns:
                self.customer_data['recent_visit_date'] = pd.to_datetime(self.customer_data['recent_visit_date'])
                
        except Exception as e:
            self.logger.error(f"DuckDB ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {e}")
            raise
        
    def prepare_cohort_data(self):
        """ì½”í˜¸íŠ¸ ë¶„ì„ì„ ìœ„í•œ ë°ì´í„° ì „ì²˜ë¦¬"""
        self.logger.info("ğŸ”„ ì½”í˜¸íŠ¸ ë°ì´í„° ì¤€ë¹„ ì¤‘...")
        
        # ë‚ ì§œ ì»¬ëŸ¼ ë³€í™˜
        self.customer_data['created_at'] = pd.to_datetime(self.customer_data['created_at'])
        self.customer_data['birthdate'] = pd.to_datetime(self.customer_data['birthdate'])
        self.reservation_data['reservation_start_at'] = pd.to_datetime(self.reservation_data['reservation_start_at'])
        
        if self.sales_data is not None and len(self.sales_data) > 0:
            self.sales_data['sales_date'] = pd.to_datetime(self.sales_data['sales_date'])
            self.sales_data['birthdate'] = pd.to_datetime(self.sales_data['birthdate'])
        
        # ê³ ê°ë³„ ì²« ì˜ˆì•½ì›” ê³„ì‚° (ì½”í˜¸íŠ¸ ê¸°ì¤€)
        customer_first_reservations = self.reservation_data.groupby('customer_id')['reservation_start_at'].min().reset_index()
        customer_first_reservations.columns = ['customer_id', 'first_reservation_date']
        customer_first_reservations['cohort_month'] = customer_first_reservations['first_reservation_date'].dt.to_period('M')
        
        # ê³ ê° ë°ì´í„°ì™€ ì²« ì˜ˆì•½ ì •ë³´ ë³‘í•©
        self.customer_data = self.customer_data.merge(
            customer_first_reservations[['customer_id', 'cohort_month', 'first_reservation_date']], 
            on='customer_id', 
            how='inner'
        )
        
        # ì˜ˆì•½ ë°ì´í„°ì— ê³ ê° ì •ë³´ ì¡°ì¸
        merged_data = self.reservation_data.merge(
            self.customer_data[['customer_id', 'cohort_month', 'first_reservation_date', 'gender', 'birthdate']], 
            on='customer_id'
        )
        
        # ì˜ˆì•½ì›” ê³„ì‚°
        merged_data['reservation_month'] = merged_data['reservation_start_at'].dt.to_period('M')
        
        # ì²« ì˜ˆì•½ í›„ ê²½ê³¼ ê°œì›” ìˆ˜ ê³„ì‚°
        merged_data['months_since_first_reservation'] = (
            merged_data['reservation_month'] - merged_data['cohort_month']
        ).apply(lambda x: x.n)
        
        # ìŒìˆ˜ ê°’ ì œê±°
        merged_data = merged_data[merged_data['months_since_first_reservation'] >= 0]
        
        # ì—°ë ¹ëŒ€ ê³„ì‚°
        current_date = pd.Timestamp.now()
        merged_data['age'] = (current_date - merged_data['birthdate']).dt.days / 365.25
        merged_data['age_group'] = pd.cut(
            merged_data['age'], 
            bins=[0, 30, 40, 50, 60, 100], 
            labels=['20-29', '30-39', '40-49', '50-59', '60+'], 
            right=False
        )
        
        self.cohort_data = merged_data
        self.logger.info(f"âœ… ì½”í˜¸íŠ¸ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {len(self.cohort_data):,}ê±´")
        
    def create_cohort_table(self, data=None):
        """ì½”í˜¸íŠ¸ í…Œì´ë¸” ìƒì„±"""
        if data is None:
            data = self.cohort_data
            
        # í˜„ì¬ ë‚ ì§œì—ì„œ ë¶ˆì™„ì „í•œ ì½”í˜¸íŠ¸ ì œì™¸ (ìµœê·¼ 2ê°œì›”)
        current_date = datetime.now()
        cutoff_date = current_date - timedelta(days=60)
        cutoff_cohort = pd.Period(cutoff_date, freq='M')
        
        # ë¶ˆì™„ì „í•œ ì½”í˜¸íŠ¸ ì œì™¸
        complete_data = data[data['cohort_month'] <= cutoff_cohort]
        
        if len(complete_data) == 0:
            self.logger.warning("âš ï¸  2ê°œì›” ê¸°ì¤€ìœ¼ë¡œëŠ” ì™„ì „í•œ ì½”í˜¸íŠ¸ê°€ ì—†ì–´ ì „ì²´ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            complete_data = data.copy()
        
        # ì½”í˜¸íŠ¸ë³„ ê³ ê° ìˆ˜ ê³„ì‚°
        cohort_sizes = complete_data.groupby('cohort_month')['customer_id'].nunique().reset_index()
        cohort_sizes.columns = ['cohort_month', 'total_customers']
        
        # ê° ì½”í˜¸íŠ¸ì˜ ì›”ë³„ í™œì„± ê³ ê° ìˆ˜ ê³„ì‚°
        cohort_table = complete_data.groupby(['cohort_month', 'months_since_first_reservation'])['customer_id'].nunique().reset_index()
        cohort_table.columns = ['cohort_month', 'period_number', 'customers']
        
        # í”¼ë²— í…Œì´ë¸” ìƒì„±
        cohort_table = cohort_table.pivot(index='cohort_month', 
                                         columns='period_number', 
                                         values='customers')
        
        # ì½”í˜¸íŠ¸ í¬ê¸°ì™€ ë³‘í•©
        cohort_sizes.set_index('cohort_month', inplace=True)
        
        # ë¦¬í…ì…˜ìœ¨ ê³„ì‚°
        cohort_table = cohort_table.divide(cohort_sizes['total_customers'], axis=0)
        
        return cohort_table, cohort_sizes
    
    def analyze_shop_cohorts(self):
        """ë§¤ì¥ë³„ ì½”í˜¸íŠ¸ ë¶„ì„"""
        self.logger.info("\nğŸª ë§¤ì¥ë³„ ì½”í˜¸íŠ¸ ë¶„ì„ ì‹œì‘...")
        
        shop_cohort_summary = []
        
        # ë§¤ì¥ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        shop_list = self.customer_data[['shop_id', 'shop_name']].drop_duplicates()
        
        for _, shop_info in shop_list.iterrows():
            shop_id = shop_info['shop_id']
            shop_name = shop_info['shop_name']
            
            # ë§¤ì¥ë³„ ë°ì´í„° í•„í„°ë§
            shop_cohort_data = self.cohort_data[self.cohort_data['shop_id'] == shop_id]
            
            if len(shop_cohort_data) == 0:
                continue
            
            # ë§¤ì¥ë³„ ì½”í˜¸íŠ¸ í…Œì´ë¸” ìƒì„±
            shop_cohort_table, shop_cohort_sizes = self.create_cohort_table(shop_cohort_data)
            
            if shop_cohort_table is None or shop_cohort_table.empty:
                continue
            
            # ë§¤ì¥ë³„ ë¦¬í…ì…˜ ì§€í‘œ ê³„ì‚°
            total_customers = shop_cohort_sizes['total_customers'].sum()
            month1_retention = shop_cohort_table[1].mean() if 1 in shop_cohort_table.columns else 0
            month3_retention = shop_cohort_table[3].mean() if 3 in shop_cohort_table.columns else 0
            month6_retention = shop_cohort_table[6].mean() if 6 in shop_cohort_table.columns else 0
            
            # ë§¤ì¥ë³„ í‰ê·  ê°ë‹¨ê°€ ê³„ì‚°
            avg_price = 0
            if self.sales_data is not None and len(self.sales_data) > 0:
                shop_sales = self.sales_data[self.sales_data['shop_id'] == shop_id]
                if len(shop_sales) > 0:
                    avg_price = shop_sales['total_amount'].mean()
            
            shop_cohort_summary.append({
                'shop_id': shop_id,
                'shop_name': shop_name,
                'total_customers': total_customers,
                'total_reservations': len(shop_cohort_data),
                'month1_retention': month1_retention,
                'month3_retention': month3_retention,
                'month6_retention': month6_retention,
                'avg_price': avg_price,
                'cohort_table': shop_cohort_table,
                'cohort_sizes': shop_cohort_sizes
            })
        
        # ê²°ê³¼ ì¶œë ¥
        shop_df = pd.DataFrame(shop_cohort_summary)
        if not shop_df.empty:
            shop_df = shop_df.sort_values('month1_retention', ascending=False)
            
            self.logger.info(f"\nğŸ“Š ë§¤ì¥ë³„ ë¦¬í…ì…˜ ë¶„ì„ ê²°ê³¼:")
            self.logger.info("=" * 100)
            self.logger.info(f"{'ìˆœìœ„':<4} {'ë§¤ì¥ëª…':<20} {'ê³ ê°ìˆ˜':<8} {'1ê°œì›”':<8} {'3ê°œì›”':<8} {'6ê°œì›”':<8} {'í‰ê· ê¸ˆì•¡':<12}")
            self.logger.info("-" * 100)
            
            for i, row in enumerate(shop_df.iterrows(), 1):
                data = row[1]
                self.logger.info(f"{i:<4} {data['shop_name']:<20} {data['total_customers']:<8,.0f} "
                              f"{data['month1_retention']:<8.1%} {data['month3_retention']:<8.1%} "
                              f"{data['month6_retention']:<8.1%} {data['avg_price']:<12,.0f}")
        
        return shop_df
    
    def create_overall_cohort_heatmap(self):
        """ì „ì²´ ì½”í˜¸íŠ¸ íˆíŠ¸ë§µ ìƒì„±"""
        self.logger.info("\nğŸ¨ ì „ì²´ ì½”í˜¸íŠ¸ íˆíŠ¸ë§µ ìƒì„± ì¤‘...")
        
        cohort_table, cohort_sizes = self.create_cohort_table()
        
        if cohort_table is None:
            self.logger.warning("âš ï¸  ì½”í˜¸íŠ¸ í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨")
            return
        
        plt.figure(figsize=(16, 10))
        
        # í†µê³„ ê³„ì‚°
        total_customers = cohort_sizes['total_customers'].sum()
        total_reservations = len(self.cohort_data)
        cohort_count = len(cohort_table)
        analysis_period = f"{cohort_table.index.min()} ~ {cohort_table.index.max()}"
        
        # í‰ê·  ë¦¬í…ì…˜ìœ¨ ê³„ì‚°
        month1_retention = cohort_table[1].mean() if 1 in cohort_table.columns else 0
        month3_retention = cohort_table[3].mean() if 3 in cohort_table.columns else 0
        month6_retention = cohort_table[6].mean() if 6 in cohort_table.columns else 0
        
        # íˆíŠ¸ë§µ ìƒì„±
        sns.heatmap(cohort_table, 
                   annot=True, 
                   fmt='.1%',
                   cmap='YlOrRd',
                   linewidths=0.5,
                   cbar_kws={'label': 'Retention Rate'})
        
        # ì œëª© ì„¤ì •
        plt.title('Overall Cohort Retention Analysis (DuckDB)', fontsize=18, pad=30, fontweight='bold')
        
        # í†µê³„ ì •ë³´ í…ìŠ¤íŠ¸
        stats_text = f"""Period: {analysis_period}  |  Total Customers: {total_customers:,}  |  Total Reservations: {total_reservations:,}  |  Cohorts: {cohort_count}
Average Retention - 1M: {month1_retention:.1%}  |  3M: {month3_retention:.1%}  |  6M: {month6_retention:.1%}"""
        
        plt.figtext(0.5, 0.95, stats_text, ha='center', va='top', fontsize=11, 
                   bbox=dict(boxstyle="round,pad=0.5", facecolor="lightgray", alpha=0.8))
        
        plt.xlabel('Months Since First Visit', fontsize=12)
        plt.ylabel('Cohort Month', fontsize=12)
        plt.xticks(rotation=0)
        plt.yticks(rotation=0)
        
        plt.tight_layout()
        plt.subplots_adjust(top=0.85)
        
        save_path = 'overall_cohort_heatmap_duckdb.png'
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        self.logger.info(f"âœ… ì „ì²´ ì½”í˜¸íŠ¸ íˆíŠ¸ë§µ ì €ì¥: {save_path}")
        
        plt.close()
    
    def run_full_analysis(self):
        """ì „ì²´ ì½”í˜¸íŠ¸ ë¶„ì„ ì‹¤í–‰"""
        try:
            self.logger.info("ğŸš€ DevEagles ì½”í˜¸íŠ¸ ë¦¬í…ì…˜ ë¶„ì„ ì‹œì‘ (DuckDB)")
            self.logger.info("="*60)
            
            # 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
            self.load_data()
            self.prepare_cohort_data()
            
            # 2. ì „ì²´ ì½”í˜¸íŠ¸ ë¶„ì„
            self.create_overall_cohort_heatmap()
            
            # 3. ë§¤ì¥ë³„ ë¶„ì„
            shop_df = self.analyze_shop_cohorts()
            
            # 4. ì¢…í•© ê²°ê³¼ ë°˜í™˜
            cohort_table, cohort_sizes = self.create_cohort_table()
            
            # ì „ì²´ ë¦¬í…ì…˜ ì§€í‘œ
            overall_1m = cohort_table[1].mean() if 1 in cohort_table.columns else 0
            overall_3m = cohort_table[3].mean() if 3 in cohort_table.columns else 0
            overall_6m = cohort_table[6].mean() if 6 in cohort_table.columns else 0
            
            # í‰ê·  ê°ë‹¨ê°€ ê³„ì‚°
            aov_results = None
            gender_aov_df = None
            age_aov_df = None
            
            if self.sales_data is not None and len(self.sales_data) > 0:
                total_sales = self.sales_data['total_amount'].sum()
                total_orders = len(self.sales_data)
                avg_order_value = total_sales / total_orders if total_orders else 0
                
                aov_results = {
                    'total_sales': total_sales,
                    'total_orders': total_orders,
                    'avg_order_value': avg_order_value
                }
                
                # ì„±ë³„ AOV
                gender_aov_df = self.sales_data.groupby('gender')['total_amount'].mean().reset_index()
                
                # ì—°ë ¹ëŒ€ë³„ AOV
                current_date = pd.Timestamp.now()
                tmp = self.sales_data.copy()
                tmp['age'] = (current_date - pd.to_datetime(tmp['birthdate'])).dt.days / 365.25
                tmp['age_group'] = pd.cut(tmp['age'], bins=[0,30,40,50,60,100], labels=['20ëŒ€','30ëŒ€','40ëŒ€','50ëŒ€','60ëŒ€+'], right=False)
                age_aov_df = tmp.groupby('age_group')['total_amount'].mean().reset_index()
            
            self.logger.info(f"\nâœ… DuckDB ê¸°ë°˜ ì½”í˜¸íŠ¸ ë¦¬í…ì…˜ ë¶„ì„ ì™„ë£Œ!")
            
            return {
                'shop_analysis': shop_df,
                'overall_cohort_table': cohort_table,
                'total_customers': len(self.customer_data),
                'total_reservations': len(self.cohort_data),
                'overall_retention': {
                    '1_month': overall_1m,
                    '3_month': overall_3m,
                    '6_month': overall_6m
                },
                'aov_results': aov_results,
                'gender_aov': gender_aov_df,
                'age_aov': age_aov_df,
                'data_source': 'DuckDB'
            }
            
        except Exception as e:
            self.logger.error(f"âŒ DuckDB ê¸°ë°˜ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            return None